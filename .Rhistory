<<<<<<< Updated upstream
Pros.GCurve$TimeFrame <- round(Pros.GCurve$TimeFrame,-2)
Pros.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop+ ItemNo, data = Pros.GCurve, FUN = c(mean),keep.names = T)
Pros.GCurve$Inst <- ifelse(Pros.GCurve$Inst > 0,1,0)
t<-poly(unique(Pros.GCurve$TimeFrame),2)
time<-as.vector(unique(Pros.GCurve$TimeFrame))
t<-cbind(t,time)
t<-as.data.frame(t)
Pros.GCurve<-Pros.GCurve[order(Pros.GCurve$TimeFrame),]
Pros.GCurve$t1<-NA
Pros.GCurve$t2<-NA
for (i in (1:nrow(Pros.GCurve))){
Pros.GCurve$t1[i]<-t[t$time==Pros.GCurve$TimeFrame[i],1]
Pros.GCurve$t2[i]<-t[t$time==Pros.GCurve$TimeFrame[i],2]
}
contrasts(Pros.GCurve$Cond)[1] <- -1
contrasts(Pros.GCurve$Pop)[1] <- -1
pros.gc.brm <- brm(Inst ~1+(t1+t2)*Pop*Cond+(0+(t1+t2)*Cond||Name) + (1+(t1+t2)*Pop*Cond||ItemNo), data=Pros.GCurve, family = "bernoulli", chains = 3, iter = 1000, warmup = 600,prior=c(set_prior ("student_t (4,0, 1)")))
print(pros.gc.brm)
Pros.GCurve$fitted <-  fitted(pros.gc.brm)
ggplot(Pros.GCurve,aes(TimeFrame,Inst,linetype = Cond)) + facet_wrap(~Pop) + stat_summary(aes(y=fitted[,1]), fun.y=mean, geom="line")+coord_cartesian(ylim=c(0,0.6))+ theme_minimal()+ theme(legend.title=element_blank(),legend.position="bottom", legend.background = element_rect(colour = "white"), strip.background = element_rect(colour = "white"),  text = element_text(size = 16, colour = "black", angle = 0), strip.text.y = element_text(size = 12, colour = "black", angle = 0))+labs(x = "Time (ms)",y = "Proportion of Trials with Looks to Target Instrument")+geom_point(data = Pros.GCurve.Points, cex = 1, colour = "black", aes(shape = Cond))
setwd("~/Dropbox/Studies/Schizophrenia/SchizFeb2015Analysis")
source("ET_Scripts_Feb2015/ET_Import.r")
source("ET_Scripts_Feb2015/proc_subj.r")
library(reshape2)
library(plyr)
library(car)
require(gdata)
require(ggplot2)
require(longitudinalData)
library(lme4)
# QUD Processing scripts
o1l1 = read.csv("./QUDData/EyeCoding/SubjData/O1L1.csv",header = T)
o1l2 = read.csv("./QUDData/EyeCoding/SubjData/O1L2.csv",header = T)
o2l1 = read.csv("./QUDData/EyeCoding/SubjData/O2L1.csv",header = T)
o2l2 = read.csv("./QUDData/EyeCoding/SubjData/O2L2.csv",header = T)
PlaceCodes = read.csv("./QUDData/EyeCoding/SubjData/PlaceCodes.csv",header =  T)
#AC_40s <- read.csv("./QUDData/EyeCoding/SubjData/AC_41Place.csv", header = T)
QUD.AC = ET_Import.NoExpand("./QUDData/EyeCoding/SubjData/3.s-CSVs/AC",o1l1,o1l2,o2l1,o2l2,PlaceCodes)
QUD.AC$Pop = "AC"
QUD.SC = ET_Import.NoExpand("./QUDData/EyeCoding/SubjData/3.s-CSVs/SC",o1l1,o1l2,o2l1,o2l2,PlaceCodes)
QUD.SC$Pop = "SC"
QUD = rbind(QUD.AC,QUD.SC)
QUD$Pop = as.factor(QUD$Pop)
contrasts(QUD$Pop)[1] <- -1
QUD$Cond = as.factor(QUD$Cond)
contrasts(QUD$Cond)[1] <- -1
#Subjects AC_42,AC_43, AC_44 were tested with their object positions mirror reversed
QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("UL","UR")] <- QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("UR","UL")]
QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("LL","LR")] <- QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("LR","LL")]
# Placement correction
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$UL = "TA"
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$UR = "TI"
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code = ifelse(QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code == "TA","TI",ifelse(QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code == "TI","TA",QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code))
QUD[QUD$Marker.Name == "UL",]$Code = as.character(QUD[QUD$Marker.Name == "UL",]$UL)
QUD[QUD$Marker.Name == "UR",]$Code = as.character(QUD[QUD$Marker.Name == "UR",]$UR)
QUD[QUD$Marker.Name == "LL",]$Code = as.character(QUD[QUD$Marker.Name == "LL",]$LL)
QUD[QUD$Marker.Name == "LR",]$Code = as.character(QUD[QUD$Marker.Name == "LR",]$LR)
QUD$Inst = 0
if (length(QUD[QUD$Code == "TI",]$Inst>0)){QUD[QUD$Code == "TI",]$Inst = 1}
QUD$TA = 0
if (length(QUD[QUD$Code == "TA",]$TA>0)){QUD[QUD$Code == "TA",]$TA =  1}
QUD$DI = 0
if (length(QUD[QUD$Code == "DI",]$DI>0)){QUD[QUD$Code == "DI",]$DI = 1}
QUD$DA = 0
if (length(QUD[QUD$Code == "DA",]$DA > 0)){QUD[QUD$Code == "DA",]$DA = 1}
QUD = QUD[QUD$Name %in% c( "AC_16",
"AC_17",
"AC_18",
"AC_19",
"AC_20",
"AC_21",
"AC_23",
"AC_24",
"AC_26",
"AC_27",
"AC_29",
"AC_30",
"AC_33",
"AC_34",
"AC_37",
"AC_39",
"AC_40",
"AC_41",
"AC_32",
"AC_43",
"AC_44",
"AC_45",
"AC_46",
"AC_36","SC_02","SC_03","SC_04","SC_05","SC_06","SC_07","SC_08","SC_09","SC_10","SC_11","SC_12","SC_13","SC_14","SC_15","SC_16","SC_17","SC_18","SC_19","SC_20","SC_21","SC_22","SC_23","SC_24","SC_25"),]
QUD$NameTrial = paste(QUD$Name,QUD$Trial, sep = "")
QUD$Name <- QUD$Name[drop=TRUE]
QUD$ExOrd = 1
QUD[QUD$Name %in% c
("AC_32","AC_33","AC_34","AC_36","AC_37","AC_38","AC_39","AC_40","AC_41","AC_42","AC_43","AC_44","AC_45","AC_46","AC_47","SC_14","SC_15","SC_16","SC_17","SC_18","SC_19","SC_20","SC_21","SC_22","SC_23","SC_24","SC_25"),]$ExOrd = 2
QUD$ExOrd = as.factor(QUD$ExOrd)
contrasts(QUD$ExOrd)[1] <- -1
ddply(QUD, .(Name,ItemNo,Cond,Pop,Verb,Prep,NP2,PrepFrame,NP2Frame), plyr::summarize, TimeFrame = c(0:max(TimeFrame))) -> QUD.Expand
QUD.Expand <- merge(QUD,QUD.Expand, by = c("Name","ItemNo","Cond","Pop","TimeFrame","Verb","Prep","NP2","PrepFrame","NP2Frame"), all= TRUE)
QUD.Expand$Inst <- t(imputation(matrix(QUD.Expand$Inst, nrow = 1),method = "locf"))
QUD.Expand$TA <- t(imputation(matrix(QUD.Expand$TA, nrow = 1),method = "locf"))
QUD.Expand$DA <- t(imputation(matrix(QUD.Expand$DA, nrow = 1),method = "locf"))
QUD.Expand$DI <- t(imputation(matrix(QUD.Expand$DI, nrow = 1),method = "locf"))
QUD.Expand <- ddply(QUD.Expand, .(Name,ItemNo), transform, Period = ifelse(TimeFrame >= NP2Frame,"NP2",ifelse(TimeFrame >= PrepFrame,"Prep","Verb")))
QUD.Expand <- ddply(QUD.Expand, .(Name,ItemNo), transform, TimeFrame = TimeFrame - NP2Frame)
QUD.Expand$TimeFrame <- QUD.Expand$TimeFrame* (1000/30)
se <- function(x){
x <- sd(x)/sqrt(24)
return(x)
}
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop, data = QUD.Expand[QUD.Expand$TimeFrame >= 0 & QUD.Expand$TimeFrame <=1200,], FUN = c(mean),keep.names = T)
QUD.GCurve$TimeFrame <- round(QUD.GCurve$TimeFrame,-2)
t<-poly(unique(QUD.GCurve$TimeFrame),2)
time<-as.vector(unique(QUD.GCurve$TimeFrame))
t<-cbind(t,time)
t<-as.data.frame(t)
QUD.GCurve<-QUD.GCurve[order(QUD.GCurve$TimeFrame),]
QUD.GCurve$t1<-NA
QUD.GCurve$t2<-NA
for (i in (1:nrow(QUD.GCurve))){
QUD.GCurve$t1[i]<-t[t$time==QUD.GCurve$TimeFrame[i],1]
QUD.GCurve$t2[i]<-t[t$time==QUD.GCurve$TimeFrame[i],2]
}
contrasts(QUD.GCurve$Cond)[1] <- -1
contrasts(QUD.GCurve$Pop)[1] <- -1
qud.gc <- lmer(Inst ~1+(t1+t2)*Pop*Cond+(1+t1+t2+Cond||Name), data=QUD.GCurve)
summary(qud.gc)
source("ET_Scripts_Feb2015/ET_Import.r")
source("ET_Scripts_Feb2015/proc_subj.r")
library(reshape2)
library(plyr)
library(car)
require(gdata)
require(ggplot2)
require(longitudinalData)
library(lme4)
# QUD Processing scripts
o1l1 = read.csv("./QUDData/EyeCoding/SubjData/O1L1.csv",header = T)
o1l2 = read.csv("./QUDData/EyeCoding/SubjData/O1L2.csv",header = T)
o2l1 = read.csv("./QUDData/EyeCoding/SubjData/O2L1.csv",header = T)
o2l2 = read.csv("./QUDData/EyeCoding/SubjData/O2L2.csv",header = T)
PlaceCodes = read.csv("./QUDData/EyeCoding/SubjData/PlaceCodes.csv",header =  T)
#AC_40s <- read.csv("./QUDData/EyeCoding/SubjData/AC_41Place.csv", header = T)
QUD.AC = ET_Import.NoExpand("./QUDData/EyeCoding/SubjData/3.s-CSVs/AC",o1l1,o1l2,o2l1,o2l2,PlaceCodes)
QUD.AC$Pop = "AC"
QUD.SC = ET_Import.NoExpand("./QUDData/EyeCoding/SubjData/3.s-CSVs/SC",o1l1,o1l2,o2l1,o2l2,PlaceCodes)
QUD.SC$Pop = "SC"
QUD = rbind(QUD.AC,QUD.SC)
QUD$Pop = as.factor(QUD$Pop)
contrasts(QUD$Pop)[1] <- -1
QUD$Cond = as.factor(QUD$Cond)
contrasts(QUD$Cond)[1] <- -1
#Subjects AC_42,AC_43, AC_44 were tested with their object positions mirror reversed
QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("UL","UR")] <- QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("UR","UL")]
QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("LL","LR")] <- QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("LR","LL")]
# Placement correction
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$UL = "TA"
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$UR = "TI"
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code = ifelse(QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code == "TA","TI",ifelse(QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code == "TI","TA",QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code))
QUD[QUD$Marker.Name == "UL",]$Code = as.character(QUD[QUD$Marker.Name == "UL",]$UL)
QUD[QUD$Marker.Name == "UR",]$Code = as.character(QUD[QUD$Marker.Name == "UR",]$UR)
QUD[QUD$Marker.Name == "LL",]$Code = as.character(QUD[QUD$Marker.Name == "LL",]$LL)
QUD[QUD$Marker.Name == "LR",]$Code = as.character(QUD[QUD$Marker.Name == "LR",]$LR)
QUD$Inst = 0
if (length(QUD[QUD$Code == "TI",]$Inst>0)){QUD[QUD$Code == "TI",]$Inst = 1}
QUD$TA = 0
if (length(QUD[QUD$Code == "TA",]$TA>0)){QUD[QUD$Code == "TA",]$TA =  1}
QUD$DI = 0
if (length(QUD[QUD$Code == "DI",]$DI>0)){QUD[QUD$Code == "DI",]$DI = 1}
QUD$DA = 0
if (length(QUD[QUD$Code == "DA",]$DA > 0)){QUD[QUD$Code == "DA",]$DA = 1}
QUD = QUD[QUD$Name %in% c( "AC_16",
"AC_17",
"AC_18",
"AC_19",
"AC_20",
"AC_21",
"AC_23",
"AC_24",
"AC_26",
"AC_27",
"AC_29",
"AC_30",
"AC_33",
"AC_34",
"AC_37",
"AC_39",
"AC_40",
"AC_41",
"AC_32",
"AC_43",
"AC_44",
"AC_45",
"AC_46",
"AC_36","SC_02","SC_03","SC_04","SC_05","SC_06","SC_07","SC_08","SC_09","SC_10","SC_11","SC_12","SC_13","SC_14","SC_15","SC_16","SC_17","SC_18","SC_19","SC_20","SC_21","SC_22","SC_23","SC_24","SC_25"),]
QUD$NameTrial = paste(QUD$Name,QUD$Trial, sep = "")
QUD$Name <- QUD$Name[drop=TRUE]
QUD$ExOrd = 1
QUD[QUD$Name %in% c
("AC_32","AC_33","AC_34","AC_36","AC_37","AC_38","AC_39","AC_40","AC_41","AC_42","AC_43","AC_44","AC_45","AC_46","AC_47","SC_14","SC_15","SC_16","SC_17","SC_18","SC_19","SC_20","SC_21","SC_22","SC_23","SC_24","SC_25"),]$ExOrd = 2
QUD$ExOrd = as.factor(QUD$ExOrd)
contrasts(QUD$ExOrd)[1] <- -1
ddply(QUD, .(Name,ItemNo,Cond,Pop,Verb,Prep,NP2,PrepFrame,NP2Frame), plyr::summarize, TimeFrame = c(0:max(TimeFrame))) -> QUD.Expand
QUD.Expand <- merge(QUD,QUD.Expand, by = c("Name","ItemNo","Cond","Pop","TimeFrame","Verb","Prep","NP2","PrepFrame","NP2Frame"), all= TRUE)
QUD.Expand$Inst <- t(imputation(matrix(QUD.Expand$Inst, nrow = 1),method = "locf"))
QUD.Expand$TA <- t(imputation(matrix(QUD.Expand$TA, nrow = 1),method = "locf"))
QUD.Expand$DA <- t(imputation(matrix(QUD.Expand$DA, nrow = 1),method = "locf"))
QUD.Expand$DI <- t(imputation(matrix(QUD.Expand$DI, nrow = 1),method = "locf"))
QUD.Expand <- ddply(QUD.Expand, .(Name,ItemNo), transform, Period = ifelse(TimeFrame >= NP2Frame,"NP2",ifelse(TimeFrame >= PrepFrame,"Prep","Verb")))
QUD.Expand <- ddply(QUD.Expand, .(Name,ItemNo), transform, TimeFrame = TimeFrame - NP2Frame)
QUD.Expand$TimeFrame <- QUD.Expand$TimeFrame* (1000/30)
se <- function(x){
x <- sd(x)/sqrt(24)
return(x)
}
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop, data = QUD.Expand[QUD.Expand$TimeFrame >= 0 & QUD.Expand$TimeFrame <=1200,], FUN = c(mean),keep.names = T)
QUD.GCurve$TimeFrame <- round(QUD.GCurve$TimeFrame,-2)
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop, data = QUD.GCurve, FUN = c(mean),keep.names = T)
t<-poly(unique(QUD.GCurve$TimeFrame),2)
time<-as.vector(unique(QUD.GCurve$TimeFrame))
t<-cbind(t,time)
t<-as.data.frame(t)
QUD.GCurve<-QUD.GCurve[order(QUD.GCurve$TimeFrame),]
QUD.GCurve$t1<-NA
QUD.GCurve$t2<-NA
for (i in (1:nrow(QUD.GCurve))){
QUD.GCurve$t1[i]<-t[t$time==QUD.GCurve$TimeFrame[i],1]
QUD.GCurve$t2[i]<-t[t$time==QUD.GCurve$TimeFrame[i],2]
}
contrasts(QUD.GCurve$Cond)[1] <- -1
contrasts(QUD.GCurve$Pop)[1] <- -1
qud.gc <- lmer(Inst ~1+(t1+t2)*Pop*Cond+(1+t1+t2+Cond||Name), data=QUD.GCurve)
summary(qud.gc)
source("ET_Scripts_Feb2015/ET_Import.r")
source("ET_Scripts_Feb2015/proc_subj.r")
library(reshape2)
library(plyr)
library(car)
require(gdata)
require(ggplot2)
require(longitudinalData)
library(lme4)
# QUD Processing scripts
o1l1 = read.csv("./QUDData/EyeCoding/SubjData/O1L1.csv",header = T)
o1l2 = read.csv("./QUDData/EyeCoding/SubjData/O1L2.csv",header = T)
o2l1 = read.csv("./QUDData/EyeCoding/SubjData/O2L1.csv",header = T)
o2l2 = read.csv("./QUDData/EyeCoding/SubjData/O2L2.csv",header = T)
PlaceCodes = read.csv("./QUDData/EyeCoding/SubjData/PlaceCodes.csv",header =  T)
#AC_40s <- read.csv("./QUDData/EyeCoding/SubjData/AC_41Place.csv", header = T)
QUD.AC = ET_Import.NoExpand("./QUDData/EyeCoding/SubjData/3.s-CSVs/AC",o1l1,o1l2,o2l1,o2l2,PlaceCodes)
QUD.AC$Pop = "AC"
QUD.SC = ET_Import.NoExpand("./QUDData/EyeCoding/SubjData/3.s-CSVs/SC",o1l1,o1l2,o2l1,o2l2,PlaceCodes)
QUD.SC$Pop = "SC"
QUD = rbind(QUD.AC,QUD.SC)
QUD$Pop = as.factor(QUD$Pop)
contrasts(QUD$Pop)[1] <- -1
QUD$Cond = as.factor(QUD$Cond)
contrasts(QUD$Cond)[1] <- -1
#Subjects AC_42,AC_43, AC_44 were tested with their object positions mirror reversed
QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("UL","UR")] <- QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("UR","UL")]
QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("LL","LR")] <- QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("LR","LL")]
# Placement correction
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$UL = "TA"
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$UR = "TI"
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code = ifelse(QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code == "TA","TI",ifelse(QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code == "TI","TA",QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code))
QUD[QUD$Marker.Name == "UL",]$Code = as.character(QUD[QUD$Marker.Name == "UL",]$UL)
QUD[QUD$Marker.Name == "UR",]$Code = as.character(QUD[QUD$Marker.Name == "UR",]$UR)
QUD[QUD$Marker.Name == "LL",]$Code = as.character(QUD[QUD$Marker.Name == "LL",]$LL)
QUD[QUD$Marker.Name == "LR",]$Code = as.character(QUD[QUD$Marker.Name == "LR",]$LR)
QUD$Inst = 0
if (length(QUD[QUD$Code == "TI",]$Inst>0)){QUD[QUD$Code == "TI",]$Inst = 1}
QUD$TA = 0
if (length(QUD[QUD$Code == "TA",]$TA>0)){QUD[QUD$Code == "TA",]$TA =  1}
QUD$DI = 0
if (length(QUD[QUD$Code == "DI",]$DI>0)){QUD[QUD$Code == "DI",]$DI = 1}
QUD$DA = 0
if (length(QUD[QUD$Code == "DA",]$DA > 0)){QUD[QUD$Code == "DA",]$DA = 1}
QUD = QUD[QUD$Name %in% c( "AC_16",
"AC_17",
"AC_18",
"AC_19",
"AC_20",
"AC_21",
"AC_23",
"AC_24",
"AC_26",
"AC_27",
"AC_29",
"AC_30",
"AC_33",
"AC_34",
"AC_37",
"AC_39",
"AC_40",
"AC_41",
"AC_32",
"AC_43",
"AC_44",
"AC_45",
"AC_46",
"AC_36","SC_02","SC_03","SC_04","SC_05","SC_06","SC_07","SC_08","SC_09","SC_10","SC_11","SC_12","SC_13","SC_14","SC_15","SC_16","SC_17","SC_18","SC_19","SC_20","SC_21","SC_22","SC_23","SC_24","SC_25"),]
QUD$NameTrial = paste(QUD$Name,QUD$Trial, sep = "")
QUD$Name <- QUD$Name[drop=TRUE]
QUD$ExOrd = 1
QUD[QUD$Name %in% c
("AC_32","AC_33","AC_34","AC_36","AC_37","AC_38","AC_39","AC_40","AC_41","AC_42","AC_43","AC_44","AC_45","AC_46","AC_47","SC_14","SC_15","SC_16","SC_17","SC_18","SC_19","SC_20","SC_21","SC_22","SC_23","SC_24","SC_25"),]$ExOrd = 2
QUD$ExOrd = as.factor(QUD$ExOrd)
contrasts(QUD$ExOrd)[1] <- -1
ddply(QUD, .(Name,ItemNo,Cond,Pop,Verb,Prep,NP2,PrepFrame,NP2Frame), plyr::summarize, TimeFrame = c(0:max(TimeFrame))) -> QUD.Expand
QUD.Expand <- merge(QUD,QUD.Expand, by = c("Name","ItemNo","Cond","Pop","TimeFrame","Verb","Prep","NP2","PrepFrame","NP2Frame"), all= TRUE)
QUD.Expand$Inst <- t(imputation(matrix(QUD.Expand$Inst, nrow = 1),method = "locf"))
QUD.Expand$TA <- t(imputation(matrix(QUD.Expand$TA, nrow = 1),method = "locf"))
QUD.Expand$DA <- t(imputation(matrix(QUD.Expand$DA, nrow = 1),method = "locf"))
QUD.Expand$DI <- t(imputation(matrix(QUD.Expand$DI, nrow = 1),method = "locf"))
QUD.Expand <- ddply(QUD.Expand, .(Name,ItemNo), transform, Period = ifelse(TimeFrame >= NP2Frame,"NP2",ifelse(TimeFrame >= PrepFrame,"Prep","Verb")))
QUD.Expand <- ddply(QUD.Expand, .(Name,ItemNo), transform, TimeFrame = TimeFrame - NP2Frame)
QUD.Expand$TimeFrame <- QUD.Expand$TimeFrame* (1000/30)
se <- function(x){
x <- sd(x)/sqrt(24)
return(x)
}
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop+ItemNo, data = QUD.Expand[QUD.Expand$TimeFrame >= 0 & QUD.Expand$TimeFrame <=1200,], FUN = c(mean),keep.names = T)
QUD.GCurve$TimeFrame <- round(QUD.GCurve$TimeFrame,-2)
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop+ItemNo, data = QUD.GCurve, FUN = c(mean),keep.names = T)
QUD.GCurve$Inst <- ifelse(QUD.GCurve$Inst > 0,1,0)
t<-poly(unique(QUD.GCurve$TimeFrame),2)
time<-as.vector(unique(QUD.GCurve$TimeFrame))
t<-cbind(t,time)
t<-as.data.frame(t)
QUD.GCurve<-QUD.GCurve[order(QUD.GCurve$TimeFrame),]
QUD.GCurve$t1<-NA
QUD.GCurve$t2<-NA
for (i in (1:nrow(QUD.GCurve))){
QUD.GCurve$t1[i]<-t[t$time==QUD.GCurve$TimeFrame[i],1]
QUD.GCurve$t2[i]<-t[t$time==QUD.GCurve$TimeFrame[i],2]
}
contrasts(QUD.GCurve$Cond)[1] <- -1
contrasts(QUD.GCurve$Pop)[1] <- -1
qud.gc <- lmer(Inst ~1+(t1+t2)*Pop*Cond+(1+t1+t2+Cond||Name), data=QUD.GCurve)
head(subset(QUD.GCurve, Item == "T1"))
summary(QUD.GCurve)
QUD.GCurve[1:10,]
QUD.GCurve[11:20,]
head(subset(QUD.GCurve, Name == "AC_18" & ItemNo == "T1"))
qud.gc.brm.full <- brm(Inst ~1+(t1+t2)*Pop*Cond+(0+(t1+t2)*Cond||Name) + (1+(t1+t2)*Pop*Cond||ItemNo), data=QUD.GCurve, family = "bernoulli", chains = 3, iter = 1000, warmup = 600,prior=c(set_prior ("student_t (4,0, 1)")))
summary(qud.gc.brm.full)
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop, data = QUD.Expand[QUD.Expand$TimeFrame >= 0 & QUD.Expand$TimeFrame <=1200,], FUN = c(mean),keep.names = T)
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop + ItemNo, data = QUD.Expand[QUD.Expand$TimeFrame >= 0 & QUD.Expand$TimeFrame <=1200,], FUN = c(mean),keep.names = T)
QUD.GCurve$Inst <- ifelse(QUD.GCurve$Inst > 0,1,0)
t<-poly(unique(QUD.GCurve$TimeFrame),2)
time<-as.vector(unique(QUD.GCurve$TimeFrame))
t<-cbind(t,time)
t<-as.data.frame(t)
QUD.GCurve<-QUD.GCurve[order(QUD.GCurve$TimeFrame),]
QUD.GCurve$t1<-NA
QUD.GCurve$t2<-NA
for (i in (1:nrow(QUD.GCurve))){
QUD.GCurve$t1[i]<-t[t$time==QUD.GCurve$TimeFrame[i],1]
QUD.GCurve$t2[i]<-t[t$time==QUD.GCurve$TimeFrame[i],2]
}
contrasts(QUD.GCurve$Cond)[1] <- -1
contrasts(QUD.GCurve$Pop)[1] <- -1
qud.gc.brm.full <- brm(Inst ~1+(t1+t2)*Pop*Cond+(0+(t1+t2)*Cond||Name) + (1+(t1+t2)*Pop*Cond||ItemNo), data=QUD.GCurve, family = "bernoulli", chains = 3, iter = 1000, warmup = 600,prior=c(set_prior ("student_t (4,0, 1)")))
summary(qud.gc.brm.full)
qud.gc.brm.full <- brm(Inst ~1+(t1+t2)*Pop*Cond+(0+(t1+t2)*Cond||Name) + (1+(t1+t2)*Pop*Cond||ItemNo), data=QUD.GCurve, family = "bernoulli", chains = 3, iter = 1000, warmup = 600,prior=c(set_prior ("student_t (6,0, 0.5)")))
summary(qud.gc.brm.full)
qud.gc.brm.full <- brm(Inst ~1+(t1+t2)*Pop*Cond+(0+(t1+t2)*Cond|Name) + (1+(t1+t2)*Pop*Cond|ItemNo), data=QUD.GCurve, family = "bernoulli", chains = 3, iter = 1000, warmup = 600,prior=c(set_prior ("student_t (6,0, 0.5)")))
summary(qud.gc.brm.full)
source("ET_Scripts_Feb2015/ET_Import.r")
source("ET_Scripts_Feb2015/proc_subj.r")
library(reshape2)
library(plyr)
library(car)
require(gdata)
require(ggplot2)
require(longitudinalData)
library(lme4)
# QUD Processing scripts
o1l1 = read.csv("./QUDData/EyeCoding/SubjData/O1L1.csv",header = T)
o1l2 = read.csv("./QUDData/EyeCoding/SubjData/O1L2.csv",header = T)
o2l1 = read.csv("./QUDData/EyeCoding/SubjData/O2L1.csv",header = T)
o2l2 = read.csv("./QUDData/EyeCoding/SubjData/O2L2.csv",header = T)
PlaceCodes = read.csv("./QUDData/EyeCoding/SubjData/PlaceCodes.csv",header =  T)
#AC_40s <- read.csv("./QUDData/EyeCoding/SubjData/AC_41Place.csv", header = T)
QUD.AC = ET_Import.NoExpand("./QUDData/EyeCoding/SubjData/3.s-CSVs/AC",o1l1,o1l2,o2l1,o2l2,PlaceCodes)
QUD.AC$Pop = "AC"
QUD.SC = ET_Import.NoExpand("./QUDData/EyeCoding/SubjData/3.s-CSVs/SC",o1l1,o1l2,o2l1,o2l2,PlaceCodes)
QUD.SC$Pop = "SC"
QUD = rbind(QUD.AC,QUD.SC)
QUD$Pop = as.factor(QUD$Pop)
contrasts(QUD$Pop)[1] <- -1
QUD$Cond = as.factor(QUD$Cond)
contrasts(QUD$Cond)[1] <- -1
#Subjects AC_42,AC_43, AC_44 were tested with their object positions mirror reversed
QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("UL","UR")] <- QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("UR","UL")]
QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("LL","LR")] <- QUD[QUD$Name %in% c("AC_42","AC_43","AC_44"),c("LR","LL")]
# Placement correction
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$UL = "TA"
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$UR = "TI"
QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code = ifelse(QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code == "TA","TI",ifelse(QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code == "TI","TA",QUD[QUD$Name == "SC_02" & QUD$ItemNo == "T5",]$Code))
QUD[QUD$Marker.Name == "UL",]$Code = as.character(QUD[QUD$Marker.Name == "UL",]$UL)
QUD[QUD$Marker.Name == "UR",]$Code = as.character(QUD[QUD$Marker.Name == "UR",]$UR)
QUD[QUD$Marker.Name == "LL",]$Code = as.character(QUD[QUD$Marker.Name == "LL",]$LL)
QUD[QUD$Marker.Name == "LR",]$Code = as.character(QUD[QUD$Marker.Name == "LR",]$LR)
QUD$Inst = 0
if (length(QUD[QUD$Code == "TI",]$Inst>0)){QUD[QUD$Code == "TI",]$Inst = 1}
QUD$TA = 0
if (length(QUD[QUD$Code == "TA",]$TA>0)){QUD[QUD$Code == "TA",]$TA =  1}
QUD$DI = 0
if (length(QUD[QUD$Code == "DI",]$DI>0)){QUD[QUD$Code == "DI",]$DI = 1}
QUD$DA = 0
if (length(QUD[QUD$Code == "DA",]$DA > 0)){QUD[QUD$Code == "DA",]$DA = 1}
QUD = QUD[QUD$Name %in% c( "AC_16",
"AC_17",
"AC_18",
"AC_19",
"AC_20",
"AC_21",
"AC_23",
"AC_24",
"AC_26",
"AC_27",
"AC_29",
"AC_30",
"AC_33",
"AC_34",
"AC_37",
"AC_39",
"AC_40",
"AC_41",
"AC_32",
"AC_43",
"AC_44",
"AC_45",
"AC_46",
"AC_36","SC_02","SC_03","SC_04","SC_05","SC_06","SC_07","SC_08","SC_09","SC_10","SC_11","SC_12","SC_13","SC_14","SC_15","SC_16","SC_17","SC_18","SC_19","SC_20","SC_21","SC_22","SC_23","SC_24","SC_25"),]
QUD$NameTrial = paste(QUD$Name,QUD$Trial, sep = "")
QUD$Name <- QUD$Name[drop=TRUE]
QUD$ExOrd = 1
QUD[QUD$Name %in% c
("AC_32","AC_33","AC_34","AC_36","AC_37","AC_38","AC_39","AC_40","AC_41","AC_42","AC_43","AC_44","AC_45","AC_46","AC_47","SC_14","SC_15","SC_16","SC_17","SC_18","SC_19","SC_20","SC_21","SC_22","SC_23","SC_24","SC_25"),]$ExOrd = 2
QUD$ExOrd = as.factor(QUD$ExOrd)
contrasts(QUD$ExOrd)[1] <- -1
ddply(QUD, .(Name,ItemNo,Cond,Pop,Verb,Prep,NP2,PrepFrame,NP2Frame), plyr::summarize, TimeFrame = c(0:max(TimeFrame))) -> QUD.Expand
QUD.Expand <- merge(QUD,QUD.Expand, by = c("Name","ItemNo","Cond","Pop","TimeFrame","Verb","Prep","NP2","PrepFrame","NP2Frame"), all= TRUE)
QUD.Expand$Inst <- t(imputation(matrix(QUD.Expand$Inst, nrow = 1),method = "locf"))
QUD.Expand$TA <- t(imputation(matrix(QUD.Expand$TA, nrow = 1),method = "locf"))
QUD.Expand$DA <- t(imputation(matrix(QUD.Expand$DA, nrow = 1),method = "locf"))
QUD.Expand$DI <- t(imputation(matrix(QUD.Expand$DI, nrow = 1),method = "locf"))
QUD.Expand <- ddply(QUD.Expand, .(Name,ItemNo), transform, Period = ifelse(TimeFrame >= NP2Frame,"NP2",ifelse(TimeFrame >= PrepFrame,"Prep","Verb")))
QUD.Expand <- ddply(QUD.Expand, .(Name,ItemNo), transform, TimeFrame = TimeFrame - NP2Frame)
QUD.Expand$TimeFrame <- QUD.Expand$TimeFrame* (1000/30)
se <- function(x){
x <- sd(x)/sqrt(24)
return(x)
}
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop+ItemNo, data = QUD.Expand[QUD.Expand$TimeFrame >= -300 & QUD.Expand$TimeFrame <=1500,], FUN = c(mean),keep.names = T)
QUD.GCurve$TimeFrame <- round(QUD.GCurve$TimeFrame,-2)
QUD.GCurve <- summaryBy(Inst+TA+DA+DI~TimeFrame+Cond+Name+Pop+ItemNo, data = QUD.GCurve, FUN = c(mean),keep.names = T)
QUD.GCurve$Inst <- ifelse(QUD.GCurve$Inst < 0,1,0)
t<-poly(unique(QUD.GCurve$TimeFrame),2)
time<-as.vector(unique(QUD.GCurve$TimeFrame))
t<-cbind(t,time)
t<-as.data.frame(t)
QUD.GCurve<-QUD.GCurve[order(QUD.GCurve$TimeFrame),]
QUD.GCurve$t1<-NA
QUD.GCurve$t2<-NA
for (i in (1:nrow(QUD.GCurve))){
QUD.GCurve$t1[i]<-t[t$time==QUD.GCurve$TimeFrame[i],1]
QUD.GCurve$t2[i]<-t[t$time==QUD.GCurve$TimeFrame[i],2]
}
contrasts(QUD.GCurve$Cond)[1] <- -1
contrasts(QUD.GCurve$Pop)[1] <- -1
qud.gc.brm.full <- brm(Inst ~1+(t1+t2)*Pop*Cond+(0+(t1+t2)*Cond|Name) + (1+(t1+t2)*Pop*Cond|ItemNo), data=QUD.GCurve, family = "bernoulli", chains = 3, iter = 1000, warmup = 600,prior=c(set_prior ("student_t (6,0, 0.5)")))
summary(qud.gc.brm.full)
qud.gc.brm.full <- brm(Inst ~1+(t1+t2)*Pop*Cond+(0+(t1+t2)*Cond|Name) + (1+(t1+t2)*Pop*Cond|ItemNo), data=QUD.GCurve, family = "bernoulli", chains = 3, iter = 1000, warmup = 600))
summary(qud.gc.brm.full)
qud.gc.brm.full <- brm(Inst ~1+(t1+t2)*Pop*Cond+(0+(t1+t2)*Cond|Name) + (1+(t1+t2)*Pop*Cond|ItemNo), data=QUD.GCurve, family = "bernoulli", chains = 3, iter = 1000, warmup = 600)
setwd("~/GitHub/CFS_Compositionality")
sklar_wide <- read.csv("Sklar_Expt1_Wide.csv")
summary(sklar_wide)
sklar_wide <- read.csv("Sklar_Expt1_Wide.csv")
summary(sklar_wide)
sklar_wide
library(readr)
Slar_Expt1_Wide <- read_csv("~/GitHub/CFS_Compositionality/Slar_Expt1_Wide.csv")
View(Slar_Expt1_Wide)
summary(Slar_Expt1_Wide)
setwd("~/GitHub/CFS_Compositionality")
sklar_wide <- read.csv("Sklar_Expt1_Wide.csv")
summary(sklar_wide)
sklar_wide <- read.csv("Slar_Expt1_Wide")
summary(sklar_wide)
sklar_wide <- read_csv("Slar_Expt1_Wide")
summary(sklar_wide)
sklar_wide <- read_csv("~/GitHub/CFS_Compositionality/Slar_Expt1_Wide")
summary(sklar_wide)
sklar_wide <- read_csv("~/GitHub/CFS_Compositionality/Slar_Expt1_Wide.csv")
sklar_wide <-read_csv("~/GitHub/CFS_Compositionality/Slar_Expt1_Wide.csv")
summary(sklar_wide)
sklar_wide <-read.csv("~/GitHub/CFS_Compositionality/Slar_Expt1_Wide.csv")
summary(sklar_wide)
gather(sklar_wide, Item, rt, paste("X",1:32,sep =""))
paste("X",1:32,sep ="")
a <- gather(sklar_wide, Item, rt, paste("X",1:33,sep =""))
a
?gather
library(tidyr)
a <- gather(sklar_wide, Item, rt, paste("X",1:33,sep =""))
summary(a)
?gather
gather(sklar_wide, Item, rt, paste("X",1:33,sep =""))
summary(sklar_wide)
=======
```{r}
qplot(age_days, idspref, col = lab, group = 1, data = diffs) +
geom_smooth(method = "lm") +
geom_hline(yintercept = 0, lty = 2) +
ylab("IDS preference (s)")
```
By age and by trial.
```{r}
qplot(age_days, idspref, col = lab, group = 1, data = diffs) +
geom_smooth(method = "lm") +
facet_wrap(~trial_num) +
geom_hline(yintercept = 0, lty = 2) +
ylab("IDS preference (s)")
```
## Hypothesis tests
### One Sample t-test against chance
Using log transformed looking time.
```{r}
d_t_test1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
t.test(d_t_test1$log_lt_diff , mu = 0)
```
### Paired t-test
As above, but perhaps it is simpler to compare conditions, as our mixed effects models will use a condition predictor. Using log transformed looking time.
```{r}
d_t_test2 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type) %>%
summarise(log_lt = mean(log_lt))
t.test(log_lt ~  trial_type, data = d_t_test2, paired = T)
```
### IDS Preference across age
#### Linear effect of age
Planned regression: 1 + CentredAge * Trial Type + (1 + Centred Age * Trial Type)\\
For some crazy reason this model won't converge in r markdown, but does converge in the console (??!), so I removed the by lab interaction
```{r}
d_lmer1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + AgeC * trial_type + (1+ AgeC + trial_type|lab), data = d_lmer1))
```
#### Quadratic effect of age
Planned regression: 1 + (CentredAge + CentredAge^2) * Trial Type + (1 + (Centred Age + CentredAge ^2) * Trial Type)\\
I removed the by lab interaction to aid convergence
```{r}
d_lmer2 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + poly(AgeC,2) * trial_type + (1+ poly(AgeC,2) + trial_type|lab), data = d_lmer2))
```
#### Secondary hypothesis tests, e.g trial order and age.
We will fit a linear mixed effects model predicting all individual observations, with the structure:\\
log(looking.time) ~ trial.num * stimulus * age + (trial.num * stimulus | subid) + (trial.num * stimulus * age | lab)\\
NB. This is taken from the RRR. Does stimulus here refer to condition or item? I have taken it to refer to condition.\\
Interactions removed to aid convergence.
```{r}
d_lmer3 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days),trial_numC = (trial_num - mean(trial_num))/sd(trial_num))
summary(lmer(log_lt ~ 1 + AgeC * trial_type * trial_numC + (1+ trial_type + trial_numC|subid)+ (1+ AgeC + trial_type + trial_numC|lab) , data = d_lmer3))
```
# Conclusions
Practical recommendations:
- Need to make standardized templates for `lab`, `subject`, and `trial` data.
- Need to develop policies for data exclusion at the subject level (e.g., any child excluded)
- Need to walk through and select the planned analyses - this is going to be tricky!
Conclusions: It looks like we're seeing some IDS preference for each group, albeit at a different part of the experiment for each age/lab combo.
options(dplyr.width = Inf)
knitr::opts_chunk$set(message = FALSE, warning = FALSE, cache=TRUE)
library(lme4)
library(tidyverse)
library(eyetrackingR)
library(stringr)
library(lubridate)
library(bit64) # necessary because of times from SMI > max integer size
library(langcog)
library(knitr)
library(forcats)
source("et_helper.R")
theme_set(theme_bw())
raw_data_path <- "pilot/frank/"
info_path <- "info/"
processed_data_path <- "processed_data/frank/"
all_data <- dir(raw_data_path, pattern="*.txt") %>%
paste0(raw_data_path, .) %>%
map_df(get_smi_header) %>%
split(.$file_name) %>%
map_df(read_smi_idf) %>%
split(.$file_name) %>%
map_df(preprocess_data)
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
info <- read_csv("info/frank_demo.csv")
frank_data <- info %>%
select(subid, age, order) %>%
left_join(frank_data)
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
floccia_data <- read_csv("pilot/floccia/pilot data.csv") %>%
rename(age_days = age,
looking_time = LT) %>%
mutate(subid = as.character(id),
method = "HPP",
stimulus = str_replace(str_replace(stimulus, ".wav", ""),
"Manybabies\\\\", "")) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = "-") %>%
mutate(trial_num = ceiling(trial/2)) %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
hamlin_path <- "pilot/hamlin/"
hamlin_data <- dir(hamlin_path, pattern="*.csv") %>%
paste0(hamlin_path, .) %>%
map_df(function(x) {read_csv(x) %>% mutate(order = x)}) %>%
mutate(order = as.numeric(str_replace(str_replace(order, ".csv",""),
"pilot/hamlin/order",""))) %>%
gather(trial, looking_time,
starts_with("Train"), starts_with("IDS"), starts_with("ADS")) %>%
separate(trial, into = c("trial_type","trial_num"), sep = -2) %>%
mutate(lab = "ubc",
method = "single-screen",
trial_num = as.numeric(trial_num),
age_days = str_split(age, ";") %>%
map_dbl(function(x) as.numeric(x[1]) * 30.3 + as.numeric(x[2]))) %>%
rename(subid = subnum) %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
d <- bind_rows(floccia_data, hamlin_data, frank_data)
kable(head(d))
d_t_test1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
t.test(d_t_test1$log_lt_diff , mu = 0)
d_lmer1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + AgeC * trial_type + (1+ AgeC + trial_type|lab), data = d_lmer1))
d_lmer1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time), AgeC = (age_days - mean(age_days))/sd(age_days))
summary(lmer(log_lt ~ 1 + AgeC * trial_type + (1+ AgeC * trial_type|lab), data = d_lmer1))
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
info <- read_csv("info/frank_demo.csv")
frank_data <- info %>%
select(subid, age, order) %>%
left_join(frank_data)
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
orders <- read_csv("info/orders.csv") %>%
gather(marker, stimulus, 2:19) %>%
rename(order = Order) %>%
filter(!str_detect(stimulus, "Train")) %>%
group_by(order) %>%
mutate(trial_num = 1:n()) %>%
separate(stimulus, into = c("trial_type", "stim_num"), sep = -2) %>%
select(-marker, -stim_num)
frank_data <- left_join(frank_data, orders) %>%
mutate(trial_num = ceiling(trial_num  / 2)) %>%
mutate(age_days = as.numeric(age),
lab = "stanford",
method = "eye-tracking") %>%
select(lab, method, subid, age_days, trial_type, trial_num, looking_time)
orders
frank_data
frank_data <- all_data %>%
group_by(file_name, trial, stimulus) %>%
summarise(looking_time = max(t_stim)) %>%
mutate(trial_cat = ifelse(str_detect(stimulus, ".jpg"), "speech","other")) %>%
filter(trial_cat == "speech") %>%
group_by(file_name) %>%
filter(trial > 5) %>%
mutate(trial_num = 1:n(),
subid = str_replace(str_replace(file_name,raw_data_path,""),
".txt",""))
frank_data
d
?C
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
d_moder1
contrasts(d_moder1$method)
d_moder1$method <- as.factor(d_moder1$method)
contrasts(d_moder1$method)
contrasts(d_moder1$method) <- contr.sum(3)
contrasts(d_moder1$method)
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time)) %>%
group_by(subid,trial_type,method,lab) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method + (1|lab), data = d_moder1))
d_moder1 <- d %>%
filter(trial_type != "Train",
looking_time != 0, !is.na(looking_time)) %>%
mutate(log_lt = log(looking_time),AgeC = (age_days - mean(age_days))/sd(age_days)) %>%
group_by(subid,trial_type,method,lab,age_days) %>%
summarise(log_lt = mean(log_lt)) %>%
group_by(subid,method,lab,age_days) %>%
filter(n() == 2) %>%
summarize(log_lt_diff = log_lt[trial_type == "IDS"] - log_lt[trial_type == "ADS"])
summary(lmer(log_lt_diff ~ method*AgeC + (1+AgeC|lab), data = d_moder1))
d_moder1
load("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis/Batch_Analysis/Expt1/expt1_kids.RDATA")
library(rstan)
print(eg_expt1_kids, pars = c("beta0","beta"))
print(eg_expt1_kids, pars = c("beta0","beta","beta_t0","beta_t","beta_s0","beta_s"))
load("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis/Batch_Analysis/Expt1/expt1_adults.RDATA")
print(eg_expt1_adults, pars = c("beta0","beta","beta_t0","beta_t","beta_s0","beta_s"))
load("~/GitHub/iPad_TurnTaking/DistrAnalyses/STAN_Analysis/Batch_Analysis/Expt2/eg_expt2_child_unpred.RDATA")
library(rstan)
print(eg_expt2_child_unpred,pars=c("beta0","beta","beta_t0","beta_t","beta_s0","beta_s"))
scale(c(0,1))
library(compute.es)
library(metafor)
library(meta)
library(ggplot2)
assumed_correlation = 0.55
meta_data_overall = read.csv("meta_analysis.csv", header = T, sep = ",")
meta_data_overall$p <- 2*pt(-abs(meta_data_overall$t), df=meta_data_overall$df)
meta_data <- meta_data_overall
raw.es = tes(meta_data$t,meta_data$sample_size,meta_data$sample_size,verbose = FALSE)
raw.es$study = meta_data$study
raw.es$modality = meta_data$modality
raw.es$age = meta_data$age
raw.es$study_exp_comb = meta_data$study_exp_comb
raw.es$lab = meta_data$lab
raw.es$t <- meta_data$t
raw.es$semantics <- meta_data$semantics
raw.es$p <- meta_data$p
# Recalc cohen's d assuming a 0.7 correlation between measure 1 and measure 2.
raw.es$d <- raw.es$t * sqrt(2*(1-assumed_correlation)/raw.es$n.1)
raw.es$d.se <- sqrt((2 * (1 - assumed_correlation)/raw.es$n.1) +
(raw.es$d^2)/(2 * raw.es$n.1))
ran.ef.raw <- rma.mv(d,V= (d.se)^2, random = ~ 1|lab/study,data = raw.es)
ran.ef.raw
ran.ef.moderated_lab_by_paper_mod_sem <- rma.mv(d,V= (d.se)^2,mods = ~ scale(age) + scale(modality) + scale(semantics), random = ~ 1|lab/study,data = raw.es, method = "ML")
contrasts(raw.es$modality)
contrasts(raw.es$modality)[1] <- -1
contrasts(raw.es$semantics)[1] <- -1
ran.ef.moderated_lab_by_paper_mod_sem <- rma.mv(d,V= (d.se)^2,mods = ~ scale(age) + modality + semantics, random = ~ 1|lab/study,data = raw.es, method = "ML")
ran.ef.moderated_lab_by_paper_mod_sem
1/0.27-1
1/(1+2.7)
1/(1+3.4)
0.5/2.7
round(1/(1+((1*0.5)/0.005))
round(1/(1+((1*0.5)/0.18)),2)
round(1/(1+((0.1*0.5)/0.18)),2)
setwd("~/GitHub/CFS_Compositionality")
library(gridExtra)
library(plyr)
library(lme4)
library(doBy)
library(ggplot2)
library(skewt)
library(fitdistrplus)
library(gamlss)
library(gamlss.dist)
library(lme4)
library(ez)
library(jsonlite)
library(ggplot2)
library(gridExtra)
library(plyr)
library(dplyr)
library(doBy)
library(sn)
read_data <- function(path_name){
list.files(path = path_name,full.names = T, pattern = ".csv") -> file_list
comp = c()
for (x in file_list){
data <- read.csv(x,header = T)
if ("perceptual.rating.reactiontime" %in% colnames(data)){
data <- subset(data, select = -perceptual.rating.reactiontime)
}
if ("X" %in% colnames(data)){
data <- subset(data, select = -X)
data$rt <- as.character(data$rt)
}
comp <- rbind(comp, data)
}
return(comp)
}
sense.pop <- read_data("./Expt1_Sensicality Study/data/")
# Make RTs numeric [need to remove timeout "none" responses to 8s]
sense.pop <- subset(sense.pop, rt != "None")
sense.pop$rt <- as.numeric(sense.pop$rt)
sense.pop$Length <- nchar(as.character(sense.pop$prime),allowNA = T)
sense.pop$Condition <- as.character(sense.pop$prime_semantics)
sense.pop[sense.pop$prime_semantics %in% c("Sklar_control_A","Sklar_control_B"),]$Condition <- "Sklar_control"
sense.pop$Condition <- as.factor(sense.pop$Condition)
# Funciton for shuffling sim'd data
shuffle_cond_sim <- function(data,shuffle = TRUE, exclude = FALSE){
if (shuffle != FALSE){
data <- data %>%
group_by(subj) %>%
mutate(cond = sample(cond))
data <- data.frame(data)
}
if (exclude != FALSE){
# [for Expt 1 only] Remove outliers by condition (less than 3sd from condition mean -- note that this is not a symmetric exclusion criterion)
data <- ddply(data, .(cond), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
}
data.summary <- summaryBy(rt ~ subj + cond, data = data, keep.names = T)
return(t.test(data.summary$rt ~ data.summary$cond)$p.value)
}
#### Simulate what happens with normal and skewed data
# Normal data without exclusions
pvals.norm <- rep(NA,100)
pvals.norm.excl <- rep(100)
a = data.frame(subj = rep(1:30, each = 60), cond = rep(rep(c(1,2), each = 30),30))
a <- a %>% group_by(subj) %>%
dplyr::mutate(rt = ifelse(cond >1, rnorm(30,jitter(0.333),jitter(1)),rnorm(30,jitter(0),jitter(1))))
a <- data.frame(a)
for (i in 1:100){
pvals.norm[i] <- shuffle_cond_sim(a, shuffle = TRUE)
pvals.norm.excl[i] <- shuffle_cond_sim(a, shuffle = TRUE,exclude = TRUE)
}
pvals.skew <- rep(NA,100)
pvals.skew.excl <- rep(NA,100)
pvals.skew.log <- rep(NA,100)
pvals.skew.excl.log <- rep(NA,100)
a.skew = data.frame(subj = rep(1:30, each = 60), cond = rep(rep(c(1,2), each = 30),30))
a.skew <- a.skew %>% group_by(subj) %>%
# dplyr::mutate(rt = ifelse(cond >1, rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5)),rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5))))
dplyr::mutate(rt = ifelse(cond >1, rexp(50,jitter(0.3)),rexp(50,jitter(0.3))))
a.skew <- data.frame(a.skew)
a.skew.log = data.frame(subj = rep(1:30, each = 60), cond = rep(rep(c(1,2), each = 30),30))
a.skew.log <- a.skew.log %>% group_by(subj) %>%
#dplyr::mutate(rt = ifelse(cond >1, rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5)),rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5))))
dplyr::mutate(rt = ifelse(cond >1, rexp(50,jitter(0.3)),rexp(50,jitter(0.3))))
a.skew.log <- data.frame(a.skew.log)
a.skew.log$rt <- log(a.skew.log$rt)
for (i in 1:100){
pvals.skew[i] <- shuffle_cond_sim(a.skew, shuffle = TRUE)
pvals.skew.excl[i] <- shuffle_cond_sim(a.skew, shuffle = TRUE,exclude = TRUE)
pvals.skew.log[i] <- shuffle_cond_sim(a.skew.log, shuffle = TRUE)
pvals.skew.excl.log[i] <- shuffle_cond_sim(a.skew.log, shuffle = TRUE,exclude = TRUE)
}
#shuffle.data <- data.frame(expt = "Normal Distr. Simulations", facet = "untransformed data", cond = "Do not exclude by condition", pvals = pvals.norm)
#shuffle.data <- rbind(shuffle.data, data.frame(expt = "Normal Distr. Simulations", facet = "untransformed data", cond = "Exclude by condition", pvals = pvals.norm.excl))
# Normal data with exclusions
shuffle.data <- data.frame(expt = "a. Exponential Simulations", facet = "untransformed data",cond = "Do not exclude by condition", pvals = pvals.skew)
shuffle.data <- rbind(shuffle.data, data.frame(expt = "a. Exponential Simulations", facet = "untransformed data",cond = "Exclude by condition", pvals = pvals.skew.excl))
shuffle.data <- rbind(shuffle.data, data.frame(expt = "b. Exponential Simulations", facet = "log transformed data", cond = "Do not exclude by condition", pvals = pvals.skew.log))
shuffle.data <- rbind(shuffle.data, data.frame(expt = "b. Exponential Simulations", facet = "log transformed data", cond = "Exclude by condition", pvals = pvals.skew.excl.log))
ggplot(shuffle.data,aes(x=pvals,..density.., col = cond))+ facet_wrap(expt~facet)+geom_freqpoly(alpha = 1, lwd = 1.5)+xlab("p values")
head(shuffle.data)
summary(shuffle.data)
summary(subset(shuffle.datam facet == "untransformed data" & cond == "Exclude by condition")$pvals)
summary(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals, "unif",0,1)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Do not exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet != "untransformed data" & cond == "Do not exclude by condition")$pvals, "punif",0,1)
pvals.skew <- rep(NA,1000)
pvals.skew.excl <- rep(NA,1000)
pvals.skew.log <- rep(NA,1000)
pvals.skew.excl.log <- rep(NA,1000)
a.skew = data.frame(subj = rep(1:30, each = 60), cond = rep(rep(c(1,2), each = 30),30))
a.skew <- a.skew %>% group_by(subj) %>%
# dplyr::mutate(rt = ifelse(cond >1, rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5)),rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5))))
dplyr::mutate(rt = ifelse(cond >1, rexp(50,jitter(0.3)),rexp(50,jitter(0.3))))
a.skew <- data.frame(a.skew)
a.skew.log = data.frame(subj = rep(1:30, each = 60), cond = rep(rep(c(1,2), each = 30),30))
a.skew.log <- a.skew.log %>% group_by(subj) %>%
#dplyr::mutate(rt = ifelse(cond >1, rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5)),rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5))))
dplyr::mutate(rt = ifelse(cond >1, rexp(50,jitter(0.3)),rexp(50,jitter(0.3))))
a.skew.log <- data.frame(a.skew.log)
a.skew.log$rt <- log(a.skew.log$rt)
for (i in 1:1000){
pvals.skew[i] <- shuffle_cond_sim(a.skew, shuffle = TRUE)
pvals.skew.excl[i] <- shuffle_cond_sim(a.skew, shuffle = TRUE,exclude = TRUE)
pvals.skew.log[i] <- shuffle_cond_sim(a.skew.log, shuffle = TRUE)
pvals.skew.excl.log[i] <- shuffle_cond_sim(a.skew.log, shuffle = TRUE,exclude = TRUE)
}
#shuffle.data <- data.frame(expt = "Normal Distr. Simulations", facet = "untransformed data", cond = "Do not exclude by condition", pvals = pvals.norm)
#shuffle.data <- rbind(shuffle.data, data.frame(expt = "Normal Distr. Simulations", facet = "untransformed data", cond = "Exclude by condition", pvals = pvals.norm.excl))
# Normal data with exclusions
shuffle.data <- data.frame(expt = "a. Exponential Simulations", facet = "untransformed data",cond = "Do not exclude by condition", pvals = pvals.skew)
shuffle.data <- rbind(shuffle.data, data.frame(expt = "a. Exponential Simulations", facet = "untransformed data",cond = "Exclude by condition", pvals = pvals.skew.excl))
shuffle.data <- rbind(shuffle.data, data.frame(expt = "b. Exponential Simulations", facet = "log transformed data", cond = "Do not exclude by condition", pvals = pvals.skew.log))
shuffle.data <- rbind(shuffle.data, data.frame(expt = "b. Exponential Simulations", facet = "log transformed data", cond = "Exclude by condition", pvals = pvals.skew.excl.log))
ggplot(shuffle.data,aes(x=pvals,..density.., col = cond))+ facet_wrap(expt~facet)+geom_freqpoly(alpha = 1, lwd = 1.5)+xlab("p values")
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Do not exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet != "untransformed data" & cond == "Do not exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet != "untransformed data" & cond == "Exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals, subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals, subset(shuffle.data, facet == "untransformed data" & cond != "Exclude by condition")$pvals)
ks.test(subset(shuffle.data, facet != "untransformed data" & cond == "Exclude by condition")$pvals, subset(shuffle.data, facet != "untransformed data" & cond != "Exclude by condition")$pvals)
pvals.skew <- rep(NA,10000)
pvals.skew.excl <- rep(NA,10000)
pvals.skew.log <- rep(NA,10000)
pvals.skew.excl.log <- rep(NA,10000)
a.skew = data.frame(subj = rep(1:30, each = 60), cond = rep(rep(c(1,2), each = 30),30))
a.skew <- a.skew %>% group_by(subj) %>%
# dplyr::mutate(rt = ifelse(cond >1, rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5)),rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5))))
dplyr::mutate(rt = ifelse(cond >1, rexp(50,jitter(0.3)),rexp(50,jitter(0.3))))
a.skew <- data.frame(a.skew)
a.skew.log = data.frame(subj = rep(1:30, each = 60), cond = rep(rep(c(1,2), each = 30),30))
a.skew.log <- a.skew.log %>% group_by(subj) %>%
#dplyr::mutate(rt = ifelse(cond >1, rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5)),rst(50,jitter(0.7),jitter(1.5),jitter(5),jitter(2.5))))
dplyr::mutate(rt = ifelse(cond >1, rexp(50,jitter(0.3)),rexp(50,jitter(0.3))))
a.skew.log <- data.frame(a.skew.log)
a.skew.log$rt <- log(a.skew.log$rt)
for (i in 1:10000){
pvals.skew[i] <- shuffle_cond_sim(a.skew, shuffle = TRUE)
pvals.skew.excl[i] <- shuffle_cond_sim(a.skew, shuffle = TRUE,exclude = TRUE)
pvals.skew.log[i] <- shuffle_cond_sim(a.skew.log, shuffle = TRUE)
pvals.skew.excl.log[i] <- shuffle_cond_sim(a.skew.log, shuffle = TRUE,exclude = TRUE)
}
#shuffle.data <- data.frame(expt = "Normal Distr. Simulations", facet = "untransformed data", cond = "Do not exclude by condition", pvals = pvals.norm)
#shuffle.data <- rbind(shuffle.data, data.frame(expt = "Normal Distr. Simulations", facet = "untransformed data", cond = "Exclude by condition", pvals = pvals.norm.excl))
# Normal data with exclusions
shuffle.data <- data.frame(expt = "a. Exponential Simulations", facet = "untransformed data",cond = "Do not exclude by condition", pvals = pvals.skew)
shuffle.data <- rbind(shuffle.data, data.frame(expt = "a. Exponential Simulations", facet = "untransformed data",cond = "Exclude by condition", pvals = pvals.skew.excl))
shuffle.data <- rbind(shuffle.data, data.frame(expt = "b. Exponential Simulations", facet = "log transformed data", cond = "Do not exclude by condition", pvals = pvals.skew.log))
shuffle.data <- rbind(shuffle.data, data.frame(expt = "b. Exponential Simulations", facet = "log transformed data", cond = "Exclude by condition", pvals = pvals.skew.excl.log))
ggplot(shuffle.data,aes(x=pvals,..density.., col = cond))+ facet_wrap(expt~facet)+geom_freqpoly(alpha = 1, lwd = 1.5)+xlab("p values")
ks.test(subset(shuffle.data, facet != "untransformed data" & cond == "Exclude by condition")$pvals, subset(shuffle.data, facet != "untransformed data" & cond != "Exclude by condition")$pvals)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals, subset(shuffle.data, facet == "untransformed data" & cond != "Exclude by condition")$pvals)
ks.test(subset(shuffle.data, facet != "untransformed data" & cond == "Exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond == "Exclude by condition")$pvals, "punif",0,1)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond != "Exclude by condition")$pvals, "punif",0,1)
?ks.test
ks.test(subset(shuffle.data, facet == "untransformed data" & cond != "Exclude by condition")$pvals, "punif",0,1, exact = TRUE)
ks.test(subset(shuffle.data, facet == "untransformed data" & cond != "Exclude by condition")$pvals, "punif",0,1, exact = FALSE)
>>>>>>> Stashed changes
