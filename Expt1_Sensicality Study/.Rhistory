summary(sense.pop.sklar)
ifelse(subset(sense.pop.sklar ,Condition == "Sklar_Control")$rt > 1.84,1,0)
ifelse(subset(sense.pop.sklar ,Condition == "Sklar_control")$rt > 1.84,1,0)
mean(ifelse(subset(sense.pop.sklar ,Condition == "Sklar_control")$rt > 1.84,1,0))
# Let's first analyze for the Sklar trials
sense.pop.sklar <- subset(sense.pop, Condition %in% c("Sklar_control", "Sklar_violation"))
# <--
total.n <- length(unique(sense.pop.sklar$SubjNo))
trials.per.subj = max(tapply(sense.pop.sklar$rt, sense.pop.sklar$SubjNo,length)) #length(sense.pop.sklar$rt)/length(unique(sense.pop.sklar$SubjNo))
# <--
# Remove outlier subjects by Accuracy and RT (mean acc must be > 0.9, mean rt must be < 3sd above group mean)
Acc <- summaryBy(match. + rt ~ SubjNo, data = subset(sense.pop.sklar), keep.names = T)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$match. > 0.9,]$SubjNo)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$rt < (mean(Acc$rt) + (3*sd(Acc$rt))),]$SubjNo)
#<--
excl.n <- length(unique(sense.pop.sklar$SubjNo))
n.trials = length(sense.pop.sklar$rt)
#<--
# Remove incorrect trials
sense.pop.sklar <- subset(sense.pop.sklar, match. == 1)
# Remove outliers by subject (less than 3sd from participant mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(SubjNo), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
mean(ifelse(subset(sense.pop.sklar ,Condition == "Sklar_control")$rt > 4.57,1,0))
shuffle_cond <- function(sense.pop.sklar,shuffle = TRUE){
if (shuffle == TRUE){
sense.pop.sklar <- sense.pop.sklar %>%
group_by(SubjNo) %>%
mutate(Condition = sample(Condition))
sense.pop.sklar <- data.frame(sense.pop.sklar)
}
# Remove outlier subjects by Accuracy and RT (mean acc must be > 0.9, mean rt must be < 3sd above group mean)
Acc <- summaryBy(match. + rt ~ sense.pop.sklar$SubjNo, data = sense.pop.sklar, keep.names = T)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$match. > 0.9,]$SubjNo)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$rt < (mean(Acc$rt) + (3*sd(Acc$rt))),]$SubjNo)
# Remove incorrect trials
sense.pop.sklar <- subset(sense.pop.sklar, match. == 1)
# Remove outliers by subject (less than 3sd from participant mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(SubjNo), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Print standard deviation
print("+/- 3 sd = ", ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T)
return(by_subj_include)
}))
# [for Expt 1 only] Remove outliers by condition (less than 3sd from condition mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Remove RTs < 200ms
sense.pop.sklar <- subset(sense.pop.sklar, rt > 0.2)
# T test (Sklar style)
sense.pop.sklar$log.rt <- log(sense.pop.sklar$rt)
sense.pop.sklar.summary <- summaryBy(rt + log.rt~ SubjNo + Condition, data = subset(sense.pop.sklar,  Condition %in% c("Sklar_violation", "Sklar_control")), keep.names = T)
t <- t.test(rt ~ Condition, data = sense.pop.sklar.summary, paired = T)
return(t)
}
sense.pop <- read_data("./Expt1_Sensicality Study/data/")
# Make RTs numeric [need to remove timeout "none" responses to 8s]
sense.pop <- subset(sense.pop, rt != "None")
sense.pop$rt <- as.numeric(sense.pop$rt)
sense.pop$Length <- nchar(as.character(sense.pop$prime),allowNA = T)
sense.pop$Condition <- as.character(sense.pop$prime_semantics)
sense.pop[sense.pop$prime_semantics %in% c("Sklar_control_A","Sklar_control_B"),]$Condition <- "Sklar_control"
sense.pop$Condition <- as.factor(sense.pop$Condition)
library(plyr)
library(lme4)
library(doBy)
library(ggplot2)
library(skewt)
library(fitdistrplus)
library(gamlss)
library(gamlss.dist)
library(lme4)
library(ez)
library(jsonlite)
library(ggplot2)
library(gridExtra)
library(plyr)
library(dplyr)
library(doBy)
library(sn)
read_data <- function(path_name){
list.files(path = path_name,full.names = T, pattern = ".csv") -> file_list
comp = c()
for (x in file_list){
data <- read.csv(x,header = T)
if ("perceptual.rating.reactiontime" %in% colnames(data)){
data <- subset(data, select = -perceptual.rating.reactiontime)
}
if ("X" %in% colnames(data)){
data <- subset(data, select = -X)
data$rt <- as.character(data$rt)
}
comp <- rbind(comp, data)
}
return(comp)
}
sense.pop <- read_data("./Expt1_Sensicality Study/data/")
# Make RTs numeric [need to remove timeout "none" responses to 8s]
sense.pop <- subset(sense.pop, rt != "None")
sense.pop$rt <- as.numeric(sense.pop$rt)
sense.pop$Length <- nchar(as.character(sense.pop$prime),allowNA = T)
sense.pop$Condition <- as.character(sense.pop$prime_semantics)
sense.pop[sense.pop$prime_semantics %in% c("Sklar_control_A","Sklar_control_B"),]$Condition <- "Sklar_control"
sense.pop$Condition <- as.factor(sense.pop$Condition)
summary(sense.pop)
setwd("~/Dropbox/Studies/CFS")
sense.pop <- read_data("./Expt1_Sensicality Study/data/")
# Make RTs numeric [need to remove timeout "none" responses to 8s]
sense.pop <- subset(sense.pop, rt != "None")
sense.pop$rt <- as.numeric(sense.pop$rt)
sense.pop$Length <- nchar(as.character(sense.pop$prime),allowNA = T)
sense.pop$Condition <- as.character(sense.pop$prime_semantics)
sense.pop[sense.pop$prime_semantics %in% c("Sklar_control_A","Sklar_control_B"),]$Condition <- "Sklar_control"
sense.pop$Condition <- as.factor(sense.pop$Condition)
shuffle_cond <- function(sense.pop.sklar,shuffle = TRUE){
if (shuffle == TRUE){
sense.pop.sklar <- sense.pop.sklar %>%
group_by(SubjNo) %>%
mutate(Condition = sample(Condition))
sense.pop.sklar <- data.frame(sense.pop.sklar)
}
# Remove outlier subjects by Accuracy and RT (mean acc must be > 0.9, mean rt must be < 3sd above group mean)
Acc <- summaryBy(match. + rt ~ sense.pop.sklar$SubjNo, data = sense.pop.sklar, keep.names = T)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$match. > 0.9,]$SubjNo)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$rt < (mean(Acc$rt) + (3*sd(Acc$rt))),]$SubjNo)
# Remove incorrect trials
sense.pop.sklar <- subset(sense.pop.sklar, match. == 1)
# Remove outliers by subject (less than 3sd from participant mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(SubjNo), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Print standard deviation
print("+/- 3 sd = ", ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T)
return(by_subj_include)
}))
# [for Expt 1 only] Remove outliers by condition (less than 3sd from condition mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Remove RTs < 200ms
sense.pop.sklar <- subset(sense.pop.sklar, rt > 0.2)
# T test (Sklar style)
sense.pop.sklar$log.rt <- log(sense.pop.sklar$rt)
sense.pop.sklar.summary <- summaryBy(rt + log.rt~ SubjNo + Condition, data = subset(sense.pop.sklar,  Condition %in% c("Sklar_violation", "Sklar_control")), keep.names = T)
t <- t.test(rt ~ Condition, data = sense.pop.sklar.summary, paired = T)
return(t)
}
sense.pop.sklar <- subset(sense.pop, Condition %in% c("Sklar_control", "Sklar_violation"))
pvals.sklar <- rep(NA,5000)
for (i in 1:5000){
t <- shuffle_cond(sense.pop.sklar)
pvals.sklar[i] <- t$p.value
}
paste("resample p = ", length(pvals.sklar[shuffle_cond(sense.pop.sklar,FALSE)$p.value > pvals.sklar])/length(pvals.sklar))
print("+/- 3 sd = ", ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T)
return(by_subj_include)
}))
print("+/- 3 sd = ", ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T)
return(by_subj_include)
}))
print("+/- 3 sd = ", ddply(sense.pop.sklar, .(Condition), function(d){ by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T) return(by_subj_include)}))
ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T)
return(by_subj_include)
})
sd = ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T)
return(by_subj_include)
})
print("+/- 3 sd = ", sd)
print(paste("+/- 3 sd = ", ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T)
return(by_subj_include)
})))
shuffle_cond <- function(sense.pop.sklar,shuffle = TRUE){
if (shuffle == TRUE){
sense.pop.sklar <- sense.pop.sklar %>%
group_by(SubjNo) %>%
mutate(Condition = sample(Condition))
sense.pop.sklar <- data.frame(sense.pop.sklar)
}
# Remove outlier subjects by Accuracy and RT (mean acc must be > 0.9, mean rt must be < 3sd above group mean)
Acc <- summaryBy(match. + rt ~ sense.pop.sklar$SubjNo, data = sense.pop.sklar, keep.names = T)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$match. > 0.9,]$SubjNo)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$rt < (mean(Acc$rt) + (3*sd(Acc$rt))),]$SubjNo)
# Remove incorrect trials
sense.pop.sklar <- subset(sense.pop.sklar, match. == 1)
# Remove outliers by subject (less than 3sd from participant mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(SubjNo), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Print standard deviation
print(paste("+/- 3 sd = ", ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <-  3*c(-1,1)*sd(d$rt,na.rm = T)
return(by_subj_include)
})))
# [for Expt 1 only] Remove outliers by condition (less than 3sd from condition mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Remove RTs < 200ms
sense.pop.sklar <- subset(sense.pop.sklar, rt > 0.2)
# T test (Sklar style)
sense.pop.sklar$log.rt <- log(sense.pop.sklar$rt)
sense.pop.sklar.summary <- summaryBy(rt + log.rt~ SubjNo + Condition, data = subset(sense.pop.sklar,  Condition %in% c("Sklar_violation", "Sklar_control")), keep.names = T)
t <- t.test(rt ~ Condition, data = sense.pop.sklar.summary, paired = T)
return(t)
}
sense.pop.sklar <- subset(sense.pop, Condition %in% c("Sklar_control", "Sklar_violation"))
pvals.sklar <- rep(NA,5000)
setwd("~/GitHub/PolysemyInduction")
library(knitr)
library(papeR)
library(skewt)
library(fitdistrplus)
library(gamlss)
library(gamlss.dist)
library(lme4)
library(ez)
library(jsonlite)
library(ggplot2)
library(gridExtra)
library(plyr)
library(dplyr)
library(doBy)
library(sn)
library(bootstrap)
Child = read.csv("./Data/Expt B/ChildData_Final.csv", header = T)
contrasts(Child$LabelType)[1] <- -1
contrasts(Child$WordType)[1] <- -1
#Child$WordType <- revalue(Child$WordType, c("Unambiguous" = "Same Kind", "Polysemous" = "Polysemous"))
Child$LabelType <- factor(Child$LabelType, levels(Child$LabelType)[c(2,1)])
Child$WordType <- factor(Child$WordType, levels(Child$WordType)[c(2,1)])
Child <- subset(Child, trial.type == "Critical")
Child <- subset(Child, Exclude == "No")
Child$AgeGroup <- "Three"
Child[Child$Age == 4,]$AgeGroup <- "Four"
Child <- Child[!Child$Age > 4 & Child$Location!="LAB",]
Child$AgeGroup <- ordered(Child$AgeGroup, levels = c("Three","Four"))
Child$AgeMoSt <- (Child$Age.Months - mean(Child$Age.Months))/sd(Child$Age.Months)
Child$Age <- as.factor(Child$Age)
Child$Loc <- "Ber"
Child[Child$Location == "Edinburgh ",]$Loc <- "Edin"
Child$Loc <- as.factor(Child$Loc)
contrasts(Child$Expln)[1] <- -1
contrasts(Child$Loc)[1] <- -1
contrasts(Child$Age)[1] <- -1
contrasts(Child$LabelType)[1] <- -1
contrasts(Child$WordType)[1] <- -1
Child$Choice <- ifelse(Child$UnrelatedChoice == 1, 0, ifelse(Child$UnrelatedChoice == 0,1,NA))
Child$Pop <- "Child"
Child$Meaning <- ifelse(Child$WordType == "Polysemous","Flexible (Thematic Relation)", "Unambiguous (Same Kind)")
Child$Meaning <- ordered(Child$Meaning, levels = c("Unambiguous (Same Kind)","Flexible (Thematic Relation)") )
Child$Label <- ifelse(Child$LabelType == "Same","Shared", "Different")
Child$Label <- ordered(Child$Label, levels = c("Shared","Different") )
Adult = read.csv("./Data/Expt B/AdultData_Final.csv", header = T)
contrasts(Adult$LabelType)[1] <- -1
contrasts(Adult$WordType)[1] <- -1
Adult$WordType <- revalue(Adult$WordType, c("Unambiguous" = "Non-Polysemous", "Polysemous" = "Polysemous"))
Adult$LabelType <- factor(Adult$LabelType, levels(Adult$LabelType)[c(2,1)])
Adult$WordType <- factor(Adult$WordType, levels(Adult$WordType)[c(2,1)])
Adult$Choice <- ifelse(Adult$UnrelatedChoice == 1, 0, ifelse(Adult$UnrelatedChoice == 0,1,NA))
Adult$Meaning <- ifelse(Adult$WordType == "Polysemous","Flexible (Thematic Relation)", "Unambiguous (Same Kind)")
Adult$Meaning <- ordered(Adult$Meaning, levels = c("Unambiguous (Same Kind)","Flexible (Thematic Relation)") )
Adult$Label <- ifelse(Adult$LabelType == "Same","Shared", "Different")
Adult$Label <- ordered(Adult$Label, levels = c("Shared","Different") )
Adult$Pop <- "Adult"
print(paste("Unambig", length(unique(subset(Adult, Meaning == "Unambiguous (Same Kind)")$SubjNo))))
print(paste("Ambig", length(unique(subset(Adult, Meaning != "Unambiguous (Same Kind)")$SubjNo))))
summary(Adult)
summaryBy(SubjNo ~ Meaning + List , data = Adult, FUN = length)
library(doBy)
emo.stims <- read.csv("all_data_with_w1w2_ratings.csv")
emo.stims <- subset(emo.stims, prime_semantics %in% c("Negative phrase","Neutral phrase"))
emo.stims <- summaryBy(MeanAffectivity + W1.score + W2.score ~ Condition + prime + prime_semantics, data = emo.stims, keep.names = T,na.rm = T)
setwd("~/Dropbox/Studies/CFS/Expt2_EmotionStudies")
library(doBy)
emo.stims <- read.csv("all_data_with_w1w2_ratings.csv")
emo.stims <- subset(emo.stims, prime_semantics %in% c("Negative phrase","Neutral phrase"))
emo.stims <- summaryBy(MeanAffectivity + W1.score + W2.score ~ Condition + prime + prime_semantics, data = emo.stims, keep.names = T,na.rm = T)
emo.stims
mean(emo.stims$W1.score)
mean(emo.stims$W2.score)
(0.22+0.449)/2
mean(c(emo.stims$W1.score,emo.stims$W2.score))
sd(c(emo.stims$W1.score,emo.stims$W2.score))
emo.stims <- read.csv("all_data_with_w1w2_ratings.csv")
summary(emo.stims)
Adult = read.csv("./Data/Expt B/AdultData_Final.csv", header = T)
Adult <- subset(Adult, Comments != "excluded becos extra subject")
Adult = read.csv("./Data/Expt B/AdultData_Final.csv", header = T)
Adult <- subset(Adult, Comments != "excluded becos extra subject")
summary(Adult)
contrasts(Adult$LabelType)[1] <- -1
contrasts(Adult$WordType)[1] <- -1
Adult$WordType <- revalue(Adult$WordType, c("Unambiguous" = "Non-Polysemous", "Polysemous" = "Polysemous"))
Adult$LabelType <- factor(Adult$LabelType, levels(Adult$LabelType)[c(2,1)])
Adult$WordType <- factor(Adult$WordType, levels(Adult$WordType)[c(2,1)])
Adult$Choice <- ifelse(Adult$UnrelatedChoice == 1, 0, ifelse(Adult$UnrelatedChoice == 0,1,NA))
Adult$Meaning <- ifelse(Adult$WordType == "Polysemous","Flexible (Thematic Relation)", "Unambiguous (Same Kind)")
Adult$Meaning <- ordered(Adult$Meaning, levels = c("Unambiguous (Same Kind)","Flexible (Thematic Relation)") )
Adult$Label <- ifelse(Adult$LabelType == "Same","Shared", "Different")
Adult$Label <- ordered(Adult$Label, levels = c("Shared","Different") )
Adult$Pop <- "Adult"
kable(summary(glmer(Choice~WordType*LabelType + (1+LabelType|SubjNo) + (1|TriadType), data = Adult, family = "binomial"))$coefficients, digits = 2)
summary(glmer(Choice~WordType*LabelType + (1+LabelType|SubjNo) + (1|TriadType), data = Adult, family = "binomial"))$coefficients
summary(glmer(Choice~WordType*LabelType + (1+LabelType|SubjNo) + (1|TriadType), data = Adult, family = "binomial"))
summary(glmer(Choice~WordType*LabelType + (1+LabelType|SubjNo) , data = Adult, family = "binomial"))
summary(glmer(Choice~WordType*LabelType + (1|SubjNo) , data = Adult, family = "binomial"))
setwd("~/Dropbox/Studies/CFS/Expt2_EmotionStudies")
emo.stims <- read.csv("all_data_with_w1w2_ratings.csv")
sklar.emo.stims <- subset(sklar.emo.stims, prime_semantics %in% c("Negative phrase","Neutral phrase"))
sklar.emo.stims <- summaryBy(MeanAffectivity + W1.score + W2.score ~ Condition + prime + prime_semantics, data = sklar.emo.stims, keep.names = T,na.rm = T)
mean(c(sklar.emo.stims$W1.score,sklar.emo.stims$W2.score))
sd(c(sklar.emo.stims$W1.score,sklar.emo.stims$W2.score))
new.emo.stims <- subset(new.emo.stims, prime_semantics %in% c("Negative phrase","Neutral phrase"))
new.emo.stims <- summaryBy(MeanAffectivity + W1.score + W2.score ~ Condition + prime + prime_semantics, data = new.emo.stims, keep.names = T,na.rm = T)
mean(c(new.emo.stims$W1.score,new.emo.stims$W2.score))
sd(c(new.emo.stims$W1.score,new.emo.stims$W2.score))
library(doBy)
emo.stims <- read.csv("all_data_with_w1w2_ratings.csv")
sklar.emo.stims <- subset(emo.stims, prime_semantics %in% c("Negative phrase","Neutral phrase"))
sklar.emo.stims <- summaryBy(MeanAffectivity + W1.score + W2.score ~ Condition + prime + prime_semantics, data = sklar.emo.stims, keep.names = T,na.rm = T)
mean(c(sklar.emo.stims$W1.score,sklar.emo.stims$W2.score))
sd(c(sklar.emo.stims$W1.score,sklar.emo.stims$W2.score))
new.emo.stims <- subset(emo.stims, prime_semantics %in% c("Negative phrase","Neutral phrase"))
new.emo.stims <- summaryBy(MeanAffectivity + W1.score + W2.score ~ Condition + prime + prime_semantics, data = new.emo.stims, keep.names = T,na.rm = T)
mean(c(new.emo.stims$W1.score,new.emo.stims$W2.score))
sd(c(new.emo.stims$W1.score,new.emo.stims$W2.score))
new.emo.stims <- subset(emo.stims, prime_semantics %in% c("Negative sentence","Neutral sentence"))
new.emo.stims <- summaryBy(MeanAffectivity + W1.score + W2.score ~ Condition + prime + prime_semantics, data = new.emo.stims, keep.names = T,na.rm = T)
mean(c(new.emo.stims$W1.score,new.emo.stims$W2.score))
sd(c(new.emo.stims$W1.score,new.emo.stims$W2.score))
summary(emo.stims)
setwd("~/Dropbox/Studies/CFS/Expt1_Sensicality Study")
library(plyr)
library(lme4)
library(doBy)
library(ggplot2)
read_data <- function(path_name){
list.files(path = path_name,full.names = T, pattern = ".csv") -> file_list
comp = c()
for (x in file_list){
data <- read.csv(x,header = T)
if ("perceptual.rating.reactiontime" %in% colnames(data)){
data <- subset(data, select = -perceptual.rating.reactiontime)
}
if ("X" %in% colnames(data)){
data <- subset(data, select = -X)
data$rt <- as.character(data$rt)
}
comp <- rbind(comp, data)
}
return(comp)
}
sense.pop <- read_data("./data/")
# Make RTs numeric [need to remove timeout "none" responses to 8s]
sense.pop <- subset(sense.pop, rt != "None")
sense.pop$rt <- as.numeric(sense.pop$rt)
sense.pop$Length <- nchar(as.character(sense.pop$prime),allowNA = T)
sense.pop$Condition <- as.character(sense.pop$prime_semantics)
sense.pop[sense.pop$prime_semantics %in% c("Sklar_control_A","Sklar_control_B"),]$Condition <- "Sklar_control"
sense.pop$Condition <- as.factor(sense.pop$Condition)
# Note that this analysis includes all of the inclusion criteria discussed by Sklar et al.
##########################################################################################################################
#
# Let's first analyze for the Sklar trials
sense.pop.sklar <- subset(sense.pop, Condition %in% c("Sklar_control", "Sklar_violation"))
# Remove outlier subjects by Accuracy and RT (mean acc must be > 0.9, mean rt must be < 3sd above group mean)
Acc <- summaryBy(match. + rt ~ SubjNo, data = subset(sense.pop.sklar), keep.names = T)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$match. > 0.9,]$SubjNo)
sense.pop.sklar <- subset(sense.pop.sklar, SubjNo %in% Acc[Acc$rt < (mean(Acc$rt) + (3*sd(Acc$rt))),]$SubjNo)
# Remove incorrect trials
sense.pop.sklar <- subset(sense.pop.sklar, match. == 1)
# Remove outliers by subject (less than 3sd from participant mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(SubjNo), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# [for Expt 1 only] Remove outliers by condition (less than 3sd from condition mean -- note that this is not a symmetric exclusion criterion)
sense.pop.sklar <- ddply(sense.pop.sklar, .(Condition), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Remove RTs < 200ms
sense.pop.sklar <- subset(sense.pop.sklar, rt > 0.2)
# T test (Sklar style)
sense.pop.sklar$log.rt <- log(sense.pop.sklar$rt)
sense.pop.sklar.summary <- summaryBy(rt + log.rt~ SubjNo + Condition, data = subset(sense.pop.sklar,  Condition %in% c("Sklar_violation", "Sklar_control")), keep.names = T)
t.test(rt ~ Condition, data = sense.pop.sklar.summary, paired = T)
t.test(log.rt ~ Condition, data = sense.pop.sklar.summary, paired = T)
# Bayes factor -- minimum effect of 0.01, maximum of 0.06, our effect = -0.03519684 and our SE = -0.03/-1.7874=  0.01678416
# lmer (Rabag style)
sense.pop.sklar.raw <- summary(lmer(rt ~ Condition + (1+Condition|SubjNo)+ (1|prime), data = subset(sense.pop.sklar,  Condition %in% c("Sklar_violation", "Sklar_control"))))
print(sense.pop.sklar.raw)
print(paste("p value = ", 2*pnorm(-abs(coef(sense.pop.sklar.raw)[,3]))))
sense.pop.sklar.log <- summary(lmer(log.rt ~ Condition + (1+Condition|SubjNo)+ (1|prime), data = subset(sense.pop.sklar,  Condition %in% c("Sklar_violation", "Sklar_control"))))
print(sense.pop.sklar.log)
print(paste("p value = ", 2*pnorm(-abs(coef(sense.pop.sklar.log)[,3]))))
##########################################################################################################################
#
# Let's now analyze for the new trials
sense.pop.new <- subset(sense.pop, Condition %in% c("Sensible", "Non-sensible"))
# Remove outlier subjects by Accuracy and RT (mean acc must be > 0.9, mean rt must be < (!!, see by trial exclusion below) 3sd from group mean)
Acc <- summaryBy(match. + rt ~ SubjNo, data = subset(sense.pop.new), keep.names = T)
sense.pop.new <- subset(sense.pop.new, SubjNo %in% Acc[Acc$match. > 0.9,]$SubjNo)
sense.pop.new <- subset(sense.pop.new, SubjNo %in% Acc[Acc$rt < (mean(Acc$rt) + (3*sd(Acc$rt))),]$SubjNo)
# Remove incorrect trials
sense.pop.new <- subset(sense.pop.new, match. == 1)
# Remove outliers by subject (less than 3sd from participant mean -- note that this is not a symmetric exclusion criterion)
sense.pop.new <- ddply(sense.pop.new, .(SubjNo), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# [for Expt 1 only] Remove outliers by condition (less than 3sd from condition mean -- note that this is not a symmetric exclusion criterion)
sense.pop.new <- ddply(sense.pop.new, .(Condition), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Remove RTs < 200ms
sense.pop.new <- subset(sense.pop.new, rt > 0.2)
# T test (Sklar style)
sense.pop.new$log.rt <- log(sense.pop.new$rt)
sense.pop.new.summary <- summaryBy(rt + log.rt~ SubjNo + Condition, data = subset(sense.pop.new,  Condition %in% c("Non-sensible","Sensible")), keep.names = T)
t.test(rt ~ Condition, data = sense.pop.new.summary, paired = T)
t.test(log.rt ~ Condition, data = sense.pop.new.summary, paired = T)
# Bayes factor -- minimum effect of 0.01, maximum of 0.06, our effect = -0.0002327283 and our SE = -0.03/-0.02217=  0.01049744
# lmer (rabag style)
sense.pop.new.raw <-summary(lmer(rt ~ Condition + (1+Condition|SubjNo)+ (1|prime), data = subset(sense.pop.new,  Condition %in% c("Non-sensible","Sensible"))))
print(sense.pop.new.raw)
print(paste("p value = ", 2*pnorm(-abs(coef(sense.pop.new.raw)[,3]))))
sense.pop.new.log <- summary(lmer(log.rt ~ Condition + (1+Condition|SubjNo)+ (1|prime), data = subset(sense.pop.new,  Condition %in% c("Non-sensible","Sensible"))))
print(sense.pop.new.log)
print(paste("p value = ", 2*pnorm(-abs(coef(sense.pop.new.log)[,3]))))
###########################################################################################################################
#
# Finally -- a quick test if longer stims are perceived faster than shorter,
sense.pop.length <- sense.pop
# Remove outlier subjects by Accuracy and RT (mean acc must be > 0.9, mean rt must be < (!!, see by trial exclusion below) 3sd from group mean)
Acc <- summaryBy(match. + rt ~ SubjNo, data = subset(sense.pop.length), keep.names = T)
sense.pop.length <- subset(sense.pop.length, SubjNo %in% Acc[Acc$match. > 0.9,]$SubjNo)
sense.pop.length <- subset(sense.pop.length, SubjNo %in% Acc[Acc$rt < (mean(Acc$rt) + (3*sd(Acc$rt))),]$SubjNo)
# Remove incorrect trials
sense.pop.length <- subset(sense.pop.length, match. == 1)
# Remove outliers by subject (less than 3sd from participant mean -- note that this is not a symmetric exclusion criterion)
sense.pop.length <- ddply(sense.pop.length, .(SubjNo), function(d){
by_subj_include <- mean(d$rt, na.rm = T) + 3*c(-1,1)*sd(d$rt,na.rm = T)
d = subset(d, rt < by_subj_include[2])
})
# Remove RTs < 200ms
sense.pop.length <- subset(sense.pop.length, rt > 0.2)
# Standardize lenth
sense.pop.length$Length <- (sense.pop.length$Length - mean(sense.pop.length$Length, na.rm = T))/sd(sense.pop.length$Length, na.rm = T)
sense.pop.length.raw <- summary(lmer(rt ~ Length + (1+Length|SubjNo), data = sense.pop.length))
print(sense.pop.length.raw)
print(paste("p value = ", 2*pnorm(-abs(coef(sense.pop.length.raw)[,3]))))
###########################################################################################################################
#
# Graphs
sense.sklar.graph <- summaryBy(rt ~ Condition + SubjNo, data = sense.pop.sklar, keep.names = T)
sense.sklar.graph <- summaryBy(rt ~ Condition, data = sense.sklar.graph, FUN = c(mean,sd))
sense.sklar.graph$SE <- sense.sklar.graph$rt.sd/sqrt(length(unique(sense.pop.sklar$SubjNo)))
sense.sklar.graph$Experiment <- "Experiment 1a \nIncongruent Phrases"
sense.new.graph <- summaryBy(rt ~ Condition + SubjNo, data = sense.pop.new, keep.names = T)
sense.new.graph <- summaryBy(rt ~ Condition, data = sense.new.graph, FUN = c(mean,sd))
sense.new.graph$SE <- sense.new.graph$rt.sd/sqrt(length(unique(sense.pop.new$SubjNo)))
sense.new.graph$Experiment <- "Experiment 1b \nReversible Sentences"
sense.graph <- rbind(sense.sklar.graph,sense.new.graph)
sense.graph$Cond_Graph <- "Violation"
sense.graph[sense.graph$Condition %in% c("Sklar_control", "Sensible"),]$Cond_Graph <- "Control"
sense.graph$Cond_Graph <- ordered(sense.graph$Cond_Graph, levels = c("Violation", "Control"))
sense.graph$rt.mean <- sense.graph$rt.mean * 1000
sense.graph$SE <- sense.graph$SE * 1000
dodge <- position_dodge(width=0.9)
ggplot(sense.graph, aes(Experiment,rt.mean, fill = Cond_Graph)) +
geom_bar(stat = "identity",  position = dodge) +
geom_errorbar(aes(ymax = sense.graph$rt.mean +
sense.graph$SE, ymin = sense.graph$rt.mean - sense.graph$SE), width=0.25, position = dodge) +
labs(fill = "Sentence Type") +
theme(axis.text.x = element_text(colour = "black", size = 12)) +
ylab("Response Time (ms)") +
xlab("") +
ylim(c(0,1750))+
scale_fill_brewer(palette = "Set1")
summary(sense.sklar.graph)
summaryBy(rt ~ Condition, data = sense.new.graph, FUN = c(mean,sd))
summaryBy(rt ~ Condition, data = sense.new.graph, FUN = sd)
summaryBy(rt ~ Condition, data = sense.new.graph, FUN = mean)
summaryBy(rt ~ Condition, data = sense.new.graph, FUN = SD)
summaryBy(rt ~ Condition, data = sense.new.graph, FUN = sd)
install.packages(c("BH", "car", "coin", "colorspace", "curl", "data.table", "DBI", "DT", "dygraphs", "effects", "estimability", "ez", "gamlss", "ggplot2", "haven", "Hmisc", "hms", "htmlwidgets", "knitr", "matrixStats", "miscTools", "mnormt", "openssl", "psych", "quantreg", "R6", "Rcpp", "RcppEigen", "reshape2", "rmarkdown", "rstan", "rstanarm", "scales", "shiny", "shinyjs", "shinystan", "shinythemes", "sjmisc", "sjPlot", "sjstats", "SparseM", "StanHeaders", "statmod", "stringdist", "stringi", "stringr", "tibble", "tidyr", "yaml"))
install.packages(c("cluster", "codetools", "foreign", "lattice", "Matrix", "mgcv", "survival"), lib="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
install.packages(c("cluster", "codetools", "foreign", "lattice", "Matrix", "mgcv", "survival"), lib = "/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
summaryBy(rt ~ Condition, data = sense.new.graph, FUN = sd)
sd(sense.new.graph$rt)
tapply(sense.new.graph$rt,sense.new.graph$Condition,sd)
summaryBy(rt ~ Condition, data = subset(sense.new.graph, Condition %in% c("Non-sensible","Sensible"), FUN = sd)
summaryBy(rt ~ Condition, data = subset(sense.new.graph, Condition %in% c("Non-sensible","Sensible")), FUN = sd)
